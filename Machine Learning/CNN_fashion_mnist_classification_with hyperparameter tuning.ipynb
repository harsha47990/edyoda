{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN fashion_mnist classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUD9TKkqU/BNyY7VD4vd6c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnON5YVbKSZO",
        "outputId": "0bad9b70-b368-4f9b-cd60-52a4698a1aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.47.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7_7CNrj7Kaok"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "id": "SWuahLjqSQxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnsit = keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "pT-46CmcKYEE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images,train_labels),(test_images,test_labels) = fashion_mnsit.load_data() "
      ],
      "metadata": {
        "id": "kF1S250KK-dK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W659Hjj73EhB",
        "outputId": "c1951da9-0337-4386-85bd-4e1c439ecba1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "fig, axs = plt.subplots(1,4, figsize=(20, 10))\n",
        "for ax, i in zip(axs, range(6)):\n",
        "    ax.imshow(train_images[i])\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "tW8K0p_jENjm",
        "outputId": "8f77d863-b4ba-4ba5-b120-5cad2e208023"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0"
      ],
      "metadata": {
        "id": "ARRqDCe9K-hA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M1k_-d8K-kT",
        "outputId": "94395a9e-687d-4d58-8728-b3b8c414dd25"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(len(train_images),28,28,1)\n",
        "test_images = test_images.reshape(len(test_images),28,28,1)"
      ],
      "metadata": {
        "id": "sgakeuAJK-my"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-qFSiKcMDtd",
        "outputId": "2302a7c3-01b0-4660-9322-d06fd11f1f55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)), \n",
        "    keras.layers.Dense(256, \"relu\"), \n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "BhrTuLWHztgh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, shuffle=True, batch_size=500, epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zs4ZescztjJ",
        "outputId": "056598dd-c2ac-4e7b-8360-68c721ab7e66"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "120/120 [==============================] - 1s 3ms/step - loss: 0.6397 - accuracy: 0.7855\n",
            "Epoch 2/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8492\n",
            "Epoch 3/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8628\n",
            "Epoch 4/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8724\n",
            "Epoch 5/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8778\n",
            "Epoch 6/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8821\n",
            "Epoch 7/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8861\n",
            "Epoch 8/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8917\n",
            "Epoch 9/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8931\n",
            "Epoch 10/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8968\n",
            "Epoch 11/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8989\n",
            "Epoch 12/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.9028\n",
            "Epoch 13/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.9056\n",
            "Epoch 14/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9083\n",
            "Epoch 15/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9102\n",
            "Epoch 16/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.9111\n",
            "Epoch 17/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9138\n",
            "Epoch 18/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9152\n",
            "Epoch 19/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9165\n",
            "Epoch 20/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2218 - accuracy: 0.9194\n",
            "Epoch 21/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9224\n",
            "Epoch 22/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9230\n",
            "Epoch 23/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2110 - accuracy: 0.9227\n",
            "Epoch 24/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9263\n",
            "Epoch 25/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9275\n",
            "Epoch 26/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9303\n",
            "Epoch 27/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1884 - accuracy: 0.9326\n",
            "Epoch 28/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 0.9320\n",
            "Epoch 29/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9345\n",
            "Epoch 30/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9349\n",
            "Epoch 31/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9356\n",
            "Epoch 32/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9367\n",
            "Epoch 33/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9386\n",
            "Epoch 34/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9412\n",
            "Epoch 35/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1635 - accuracy: 0.9419\n",
            "Epoch 36/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9425\n",
            "Epoch 37/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1581 - accuracy: 0.9437\n",
            "Epoch 38/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1541 - accuracy: 0.9452\n",
            "Epoch 39/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9488\n",
            "Epoch 40/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1475 - accuracy: 0.9482\n",
            "Epoch 41/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9487\n",
            "Epoch 42/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9493\n",
            "Epoch 43/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9483\n",
            "Epoch 44/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9520\n",
            "Epoch 45/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9517\n",
            "Epoch 46/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9537\n",
            "Epoch 47/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9552\n",
            "Epoch 48/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9552\n",
            "Epoch 49/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9544\n",
            "Epoch 50/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9563\n",
            "Epoch 51/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9588\n",
            "Epoch 52/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9594\n",
            "Epoch 53/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9618\n",
            "Epoch 54/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1152 - accuracy: 0.9595\n",
            "Epoch 55/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 0.9615\n",
            "Epoch 56/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9605\n",
            "Epoch 57/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9629\n",
            "Epoch 58/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.9636\n",
            "Epoch 59/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9642\n",
            "Epoch 60/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0995 - accuracy: 0.9659\n",
            "Epoch 61/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.1023 - accuracy: 0.9644\n",
            "Epoch 62/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9693\n",
            "Epoch 63/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9691\n",
            "Epoch 64/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9678\n",
            "Epoch 65/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9692\n",
            "Epoch 66/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9702\n",
            "Epoch 67/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9681\n",
            "Epoch 68/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9708\n",
            "Epoch 69/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9725\n",
            "Epoch 70/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0875 - accuracy: 0.9697\n",
            "Epoch 71/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9721\n",
            "Epoch 72/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0805 - accuracy: 0.9735\n",
            "Epoch 73/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9717\n",
            "Epoch 74/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9735\n",
            "Epoch 75/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9765\n",
            "Epoch 76/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0726 - accuracy: 0.9763\n",
            "Epoch 77/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9748\n",
            "Epoch 78/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9770\n",
            "Epoch 79/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9737\n",
            "Epoch 80/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9772\n",
            "Epoch 81/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9776\n",
            "Epoch 82/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9780\n",
            "Epoch 83/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9781\n",
            "Epoch 84/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.9791\n",
            "Epoch 85/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9765\n",
            "Epoch 86/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.9796\n",
            "Epoch 87/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9794\n",
            "Epoch 88/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9828\n",
            "Epoch 89/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9796\n",
            "Epoch 90/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9829\n",
            "Epoch 91/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9793\n",
            "Epoch 92/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9804\n",
            "Epoch 93/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9820\n",
            "Epoch 94/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9825\n",
            "Epoch 95/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9835\n",
            "Epoch 96/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9837\n",
            "Epoch 97/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9839\n",
            "Epoch 98/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9851\n",
            "Epoch 99/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9843\n",
            "Epoch 100/100\n",
            "120/120 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9831\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d467724d0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, shuffle=True, batch_size=500, epochs=100,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk8IUN24IlcE",
        "outputId": "7510dd82-e942-4b07-e7f3-9ec3eee2c61b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "96/96 [==============================] - 1s 8ms/step - loss: 0.0499 - accuracy: 0.9842 - val_loss: 0.0450 - val_accuracy: 0.9858\n",
            "Epoch 2/100\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 0.0486 - val_accuracy: 0.9838\n",
            "Epoch 3/100\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 0.0507 - val_accuracy: 0.9818\n",
            "Epoch 4/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9887 - val_loss: 0.0611 - val_accuracy: 0.9772\n",
            "Epoch 5/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9862 - val_loss: 0.0557 - val_accuracy: 0.9803\n",
            "Epoch 6/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9849 - val_loss: 0.0555 - val_accuracy: 0.9812\n",
            "Epoch 7/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.0681 - val_accuracy: 0.9761\n",
            "Epoch 8/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9883 - val_loss: 0.0565 - val_accuracy: 0.9808\n",
            "Epoch 9/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9886 - val_loss: 0.0591 - val_accuracy: 0.9781\n",
            "Epoch 10/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0673 - val_accuracy: 0.9762\n",
            "Epoch 11/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9886 - val_loss: 0.0721 - val_accuracy: 0.9735\n",
            "Epoch 12/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 0.0631 - val_accuracy: 0.9766\n",
            "Epoch 13/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9914 - val_loss: 0.0655 - val_accuracy: 0.9760\n",
            "Epoch 14/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 0.0596 - val_accuracy: 0.9783\n",
            "Epoch 15/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.0597 - val_accuracy: 0.9783\n",
            "Epoch 16/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0327 - accuracy: 0.9907 - val_loss: 0.0624 - val_accuracy: 0.9767\n",
            "Epoch 17/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0683 - val_accuracy: 0.9737\n",
            "Epoch 18/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 0.0768 - val_accuracy: 0.9713\n",
            "Epoch 19/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9916 - val_loss: 0.0752 - val_accuracy: 0.9704\n",
            "Epoch 20/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9892 - val_loss: 0.0780 - val_accuracy: 0.9703\n",
            "Epoch 21/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9904 - val_loss: 0.0721 - val_accuracy: 0.9722\n",
            "Epoch 22/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.0734 - val_accuracy: 0.9712\n",
            "Epoch 23/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.0679 - val_accuracy: 0.9737\n",
            "Epoch 24/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0729 - val_accuracy: 0.9723\n",
            "Epoch 25/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0783 - val_accuracy: 0.9695\n",
            "Epoch 26/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9934 - val_loss: 0.0740 - val_accuracy: 0.9730\n",
            "Epoch 27/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.0705 - val_accuracy: 0.9728\n",
            "Epoch 28/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.0761 - val_accuracy: 0.9712\n",
            "Epoch 29/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.0782 - val_accuracy: 0.9722\n",
            "Epoch 30/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 0.0816 - val_accuracy: 0.9714\n",
            "Epoch 31/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 0.0947 - val_accuracy: 0.9657\n",
            "Epoch 32/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 0.0861 - val_accuracy: 0.9672\n",
            "Epoch 33/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 0.0790 - val_accuracy: 0.9703\n",
            "Epoch 34/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.0865 - val_accuracy: 0.9688\n",
            "Epoch 35/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.0816 - val_accuracy: 0.9702\n",
            "Epoch 36/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.0812 - val_accuracy: 0.9694\n",
            "Epoch 37/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9954 - val_loss: 0.0828 - val_accuracy: 0.9701\n",
            "Epoch 38/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.0851 - val_accuracy: 0.9696\n",
            "Epoch 39/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.0907 - val_accuracy: 0.9666\n",
            "Epoch 40/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9947 - val_loss: 0.1045 - val_accuracy: 0.9641\n",
            "Epoch 41/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.0852 - val_accuracy: 0.9689\n",
            "Epoch 42/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.0820 - val_accuracy: 0.9689\n",
            "Epoch 43/100\n",
            "96/96 [==============================] - 1s 6ms/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: 0.0864 - val_accuracy: 0.9676\n",
            "Epoch 44/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9967 - val_loss: 0.0869 - val_accuracy: 0.9680\n",
            "Epoch 45/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.0882 - val_accuracy: 0.9674\n",
            "Epoch 46/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.0928 - val_accuracy: 0.9646\n",
            "Epoch 47/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.1223 - val_accuracy: 0.9567\n",
            "Epoch 48/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.1254 - val_accuracy: 0.9581\n",
            "Epoch 49/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.1175 - val_accuracy: 0.9586\n",
            "Epoch 50/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.1140 - val_accuracy: 0.9592\n",
            "Epoch 51/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9868 - val_loss: 0.1197 - val_accuracy: 0.9584\n",
            "Epoch 52/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.1086 - val_accuracy: 0.9605\n",
            "Epoch 53/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.1020 - val_accuracy: 0.9634\n",
            "Epoch 54/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.1134 - val_accuracy: 0.9601\n",
            "Epoch 55/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.1121 - val_accuracy: 0.9625\n",
            "Epoch 56/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0980 - val_accuracy: 0.9656\n",
            "Epoch 57/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.1228 - val_accuracy: 0.9575\n",
            "Epoch 58/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.1275 - val_accuracy: 0.9555\n",
            "Epoch 59/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.1093 - val_accuracy: 0.9617\n",
            "Epoch 60/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9977 - val_loss: 0.1185 - val_accuracy: 0.9586\n",
            "Epoch 61/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.1208 - val_accuracy: 0.9582\n",
            "Epoch 62/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.1068 - val_accuracy: 0.9626\n",
            "Epoch 63/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.1157 - val_accuracy: 0.9610\n",
            "Epoch 64/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.1208 - val_accuracy: 0.9602\n",
            "Epoch 65/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.1233 - val_accuracy: 0.9600\n",
            "Epoch 66/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.1220 - val_accuracy: 0.9590\n",
            "Epoch 67/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.1136 - val_accuracy: 0.9617\n",
            "Epoch 68/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.1289 - val_accuracy: 0.9572\n",
            "Epoch 69/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.1278 - val_accuracy: 0.9591\n",
            "Epoch 70/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 0.1631 - val_accuracy: 0.9504\n",
            "Epoch 71/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.1500 - val_accuracy: 0.9529\n",
            "Epoch 72/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0274 - accuracy: 0.9901 - val_loss: 0.1660 - val_accuracy: 0.9487\n",
            "Epoch 73/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.1271 - val_accuracy: 0.9569\n",
            "Epoch 74/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.1311 - val_accuracy: 0.9583\n",
            "Epoch 75/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.1182 - val_accuracy: 0.9599\n",
            "Epoch 76/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 0.1172 - val_accuracy: 0.9606\n",
            "Epoch 77/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1277 - val_accuracy: 0.9588\n",
            "Epoch 78/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.1335 - val_accuracy: 0.9584\n",
            "Epoch 79/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.1255 - val_accuracy: 0.9603\n",
            "Epoch 80/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.1338 - val_accuracy: 0.9567\n",
            "Epoch 81/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.1584 - val_accuracy: 0.9500\n",
            "Epoch 82/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0322 - accuracy: 0.9884 - val_loss: 0.1743 - val_accuracy: 0.9470\n",
            "Epoch 83/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.1351 - val_accuracy: 0.9563\n",
            "Epoch 84/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1297 - val_accuracy: 0.9582\n",
            "Epoch 85/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9993 - val_loss: 0.1291 - val_accuracy: 0.9571\n",
            "Epoch 86/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.1273 - val_accuracy: 0.9591\n",
            "Epoch 87/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9994 - val_loss: 0.1269 - val_accuracy: 0.9576\n",
            "Epoch 88/100\n",
            "96/96 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.1315 - val_accuracy: 0.9582\n",
            "Epoch 89/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.1406 - val_accuracy: 0.9545\n",
            "Epoch 90/100\n",
            "96/96 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.1360 - val_accuracy: 0.9571\n",
            "Epoch 91/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.1815 - val_accuracy: 0.9484\n",
            "Epoch 92/100\n",
            "96/96 [==============================] - 1s 5ms/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 93/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.2065 - val_accuracy: 0.9429\n",
            "Epoch 94/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.1753 - val_accuracy: 0.9487\n",
            "Epoch 95/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.1628 - val_accuracy: 0.9513\n",
            "Epoch 96/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.1464 - val_accuracy: 0.9547\n",
            "Epoch 97/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.1506 - val_accuracy: 0.9531\n",
            "Epoch 98/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.1406 - val_accuracy: 0.9576\n",
            "Epoch 99/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.1382 - val_accuracy: 0.9568\n",
            "Epoch 100/100\n",
            "96/96 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.1455 - val_accuracy: 0.9552\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2d4601f5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = keras.Sequential([\n",
        "          keras.layers.Conv2D(\n",
        "              filters = hp.Int('conv1_filter',min_value=32,max_value=128,step =16),\n",
        "              kernel_size=hp.Choice('conv1_kernal',values = [3,5]),\n",
        "              activation = 'relu',\n",
        "              input_shape=(28,28,1)\n",
        "          ),\n",
        "\n",
        "          keras.layers.Conv2D(\n",
        "              filters = hp.Int('conv2_filter',min_value =32,max_value = 64, step = 16),\n",
        "              kernel_size = hp.Choice('cov2_kernal',values=[3,5]),\n",
        "              activation= 'relu'\n",
        "          ),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(\n",
        "              units = hp.Int('dense1_units',min_value=32,max_value=128, step=16),\n",
        "              activation='relu'\n",
        "          ),\n",
        "          keras.layers.Dense(10,activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer = keras.optimizers.Adam(hp.Choice('learning_rate',values=[2e-3,1e-3])),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "UzQ0nio0MD-5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jqu9aYNCT8Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "OK14HwApPta3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_search = kt.RandomSearch(build_model,objective = 'val_accuracy',max_trials = 5,overwrite=True)"
      ],
      "metadata": {
        "id": "nLqv8BYDPth9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_search.search(train_images, train_labels, epochs=5, validation_split=0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJkFvOlFT9JE",
        "outputId": "d30bfd7e-669d-4534-e46d-40c997a25f39"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 32s]\n",
            "val_accuracy: 0.9069333076477051\n",
            "\n",
            "Best val_accuracy So Far: 0.9107999801635742\n",
            "Total elapsed time: 00h 03m 21s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model2(hp):\n",
        "  model = keras.Sequential([\n",
        "          keras.layers.Conv2D(\n",
        "              filters = hp.Int('conv1_filter',min_value=32,max_value=128,step =16),\n",
        "              kernel_size=hp.Choice('conv1_kernal',values = [3,5]),\n",
        "              activation = 'relu',\n",
        "              input_shape=(28,28)\n",
        "          ),\n",
        "          keras.layers.Flatten(),\n",
        "          keras.layers.Dense(\n",
        "              units = hp.Int('dense1_units',min_value=32,max_value=500, step=16),\n",
        "              activation='relu'\n",
        "          ),\n",
        "          keras.layers.Dense(10,activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer = keras.optimizers.Adam(hp.Choice('learning_rate',values=[2e-3,1e-3])),\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "PwBZuGj8Ptmc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_search = kt.RandomSearch(build_model,objective = 'val_accuracy',max_trials = 5,overwrite=True)\n",
        "tuner_search.search(train_images, train_labels, epochs=5, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc0iImARPtpv",
        "outputId": "44bca02e-9f01-433d-c9cf-6e43d7c7f343"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 42s]\n",
            "val_accuracy: 0.9089999794960022\n",
            "\n",
            "Best val_accuracy So Far: 0.9183333516120911\n",
            "Total elapsed time: 00h 03m 16s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rAHPmB2bJASj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Best accuracy: 0.9998 -Best val_accuracy: 0.9552**"
      ],
      "metadata": {
        "id": "QmhvIW3EJA-K"
      }
    }
  ]
}
