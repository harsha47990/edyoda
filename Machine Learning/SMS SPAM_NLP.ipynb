{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00691c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6918943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.read_csv(r'C:\\Users\\52296881\\Downloads\\spam.csv',encoding='Windows-1252')\n",
    "df = df[['v1','v2']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e66614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v1']=df['v1'].apply(lambda x: 0 if x == 'ham' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1bfed1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5567    1\n",
       "5568    0\n",
       "5569    0\n",
       "5570    0\n",
       "5571    0\n",
       "Name: v1, Length: 5572, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9539c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f33eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d763dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5d498f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "corpus = []\n",
    "for row in range(len(df)):\n",
    "    msg=df.iloc[row,1].lower()\n",
    "    msg=nltk.word_tokenize(msg)\n",
    "    msg=[lemmatizer.lemmatize(word) for word in msg if not word in set(stopwords.words('english'))]\n",
    "    msg=' '.join(msg)\n",
    "    corpus.append(msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2a49e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69623\n",
      "8841\n"
     ]
    }
   ],
   "source": [
    "full_corpus=' '.join(corpus)\n",
    "words_corpus=full_corpus.split()\n",
    "print(len(words_corpus))\n",
    "print(len(set(words_corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71c8e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef079b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47a40f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b919721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8eb1f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(features,df['v1'],test_size=0.3,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d6a0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c2f1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier(n_neighbors=49)\n",
    "mnb = MultinomialNB(alpha=0.2)\n",
    "dtc = DecisionTreeClassifier(min_samples_split=7, random_state=111)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=31, random_state=111)\n",
    "abc = AdaBoostClassifier(n_estimators=62, random_state=111)\n",
    "bc = BaggingClassifier(n_estimators=9, random_state=111)\n",
    "etc = ExtraTreesClassifier(n_estimators=9, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a83c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {'SVC' : svc,'KN' : knc, 'NB': mnb, 'DT': dtc, 'LR': lrc, 'RF': rfc, 'AdaBoost': abc, 'BgC': bc, 'ETC': etc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a486c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, feature_train, labels_train):    \n",
    "    clf.fit(feature_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7e09ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(clf, features):\n",
    "    return (clf.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ffa7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = []\n",
    "for k,v in clfs.items():\n",
    "    train_classifier(v, x_train, y_train)\n",
    "    pred = predict_labels(v,x_test)\n",
    "    pred_scores.append((k, [accuracy_score(y_test,pred)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d01a156f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SVC', [0.9820574162679426]),\n",
       " ('KN', [0.9431818181818182]),\n",
       " ('NB', [0.986244019138756]),\n",
       " ('DT', [0.972488038277512]),\n",
       " ('LR', [0.9629186602870813]),\n",
       " ('RF', [0.9808612440191388]),\n",
       " ('AdaBoost', [0.972488038277512]),\n",
       " ('BgC', [0.9778708133971292]),\n",
       " ('ETC', [0.979066985645933])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66338143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
