{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Translation_encoder_decoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ULEAfxF-R_-",
        "outputId": "edf59339-8693-4e83-c34f-7c4cd0764f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting helper\n",
            "  Downloading helper-2.5.0.tar.gz (18 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from helper) (3.13)\n",
            "Building wheels for collected packages: helper\n",
            "  Building wheel for helper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for helper: filename=helper-2.5.0-py2.py3-none-any.whl size=19188 sha256=acda953211f52764dbb04958335a5f6257582fc013061d228bc8e33e92ecaa5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/68/52/33a3eed6a95667d7b9a38afeee13928e3f95912753f1120633\n",
            "Successfully built helper\n",
            "Installing collected packages: helper\n",
            "Successfully installed helper-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install helper\n",
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import pandas as pd\n",
        "\n",
        "english = pd.read_csv('https://raw.githubusercontent.com/Kulbear/deep-learning-nano-foundation/master/DLND-language-translation/data/small_vocab_en',sep=';',names=['data'])\n",
        "french = pd.read_csv('https://raw.githubusercontent.com/Kulbear/deep-learning-nano-foundation/master/DLND-language-translation/data/small_vocab_fr',sep=';',names=['data'])\n",
        "\n",
        "\n",
        "def sentence_padding(x,length=None):\n",
        "  return pad_sequences(x, maxlen=length, padding='post')\n",
        "\n",
        "\n",
        "def inverse_to_text(logits,tokenizer):\n",
        "  index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = ''\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "  #Returns the indices of the maximum values along an axis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_tokenize(input,in_token_index,ouput,out_token_index):\n",
        "  counter = 0\n",
        "  for sample in input:                                 \n",
        "    for considered_word in sample.split():\n",
        "      if considered_word not in in_token_index:\n",
        "        in_token_index.update({considered_word : counter + 1})\n",
        "        counter = counter + 1\n",
        "  in_max_length = max([len(i.split()) for i in input])\n",
        "\n",
        "  counter = 0\n",
        "  for sample in ouput:                                 \n",
        "    for considered_word in sample.split():\n",
        "      if considered_word not in out_token_index:\n",
        "        out_token_index.update({considered_word : counter + 1})\n",
        "        counter = counter + 1\n",
        "  out_max_length = max([len(i.split()) for i in ouput])\n",
        "\n",
        "  max_length = max([in_max_length,out_max_length])\n",
        "\n",
        "  features = max([max(in_token_index.values()) + 1,max(out_token_index.values()) + 1])\n",
        "\n",
        "  in_results  = np.zeros(shape = (len(input), max_length, features))  \n",
        "  out_results = np.zeros(shape = (len(ouput), max_length, features))\n",
        "\n",
        "  for i, sample in enumerate(input): \n",
        "    for j, considered_word in list(enumerate(sample.split())):\n",
        "      index = in_token_index.get(considered_word)\n",
        "      in_results[i, j, index] = 1\n",
        "  \n",
        "  for i, sample in enumerate(ouput): \n",
        "    for j, considered_word in list(enumerate(sample.split())):\n",
        "      index = out_token_index.get(considered_word)\n",
        "      out_results[i, j, index] = 1. \n",
        "\n",
        "  #tok.fit_on_texts(lst_sentences)\n",
        "  return in_results,out_results"
      ],
      "metadata": {
        "id": "Z2t9oWv7aVCx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_token_index = {}\n",
        "french_token_index = {}\n",
        "eng_input,french_output = sentence_tokenize(english['data'][0:1000],eng_token_index,french['data'][0:1000],french_token_index)\n",
        "print(eng_input.shape)\n",
        "print(french_output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84OEaURDi1T",
        "outputId": "382aaec3-fa76-4057-87cd-5ad2abd8e509"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 21, 263)\n",
            "(1000, 21, 263)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_decoder(input_shape):\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.05\n",
        "    \n",
        "    # TODO: Build the layers\n",
        "\n",
        "    model = Sequential()\n",
        "    (timesteps,n_features) = input_shape[1:3]\n",
        "\n",
        "    model.add(Bidirectional(LSTM(64, activation='relu', input_shape=(timesteps,n_features), return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64, activation='relu', return_sequences=False)))\n",
        "    model.add(RepeatVector(timesteps))\n",
        "    model.add(Bidirectional(LSTM(64, activation='relu', return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(128, activation='relu', return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64, activation='relu', return_sequences=True)))\n",
        "    model.add(TimeDistributed(Dense(n_features,activation='sigmoid', kernel_initializer='glorot_uniform')))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Train and Print prediction(s)\n",
        "embed_rnn_model = encoder_decoder(eng_input.shape)\n",
        "\n",
        "\n",
        "embed_rnn_model.fit(eng_input, french_output, batch_size=64, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sX96r4PDiOY",
        "outputId": "e2bef9e9-7527-4931-d9a2-4e7d1621417a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 79s 751ms/step - loss: 3.7468 - accuracy: 0.0626 - val_loss: 3.4262 - val_accuracy: 0.0645\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 8s 602ms/step - loss: 3.3618 - accuracy: 0.0583 - val_loss: 3.1234 - val_accuracy: 0.0671\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 13s 1s/step - loss: 3.0521 - accuracy: 0.0633 - val_loss: 2.8963 - val_accuracy: 0.0579\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 8s 623ms/step - loss: 2.8473 - accuracy: 0.0599 - val_loss: 2.7806 - val_accuracy: 0.0576\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 8s 608ms/step - loss: 2.7494 - accuracy: 0.0483 - val_loss: 2.7006 - val_accuracy: 0.0414\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 8s 622ms/step - loss: 2.6853 - accuracy: 0.0505 - val_loss: 2.6352 - val_accuracy: 0.0414\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 8s 598ms/step - loss: 2.6073 - accuracy: 0.0492 - val_loss: 2.5569 - val_accuracy: 0.0414\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 8s 601ms/step - loss: 2.5068 - accuracy: 0.0515 - val_loss: 2.4847 - val_accuracy: 0.0650\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 8s 592ms/step - loss: 2.4054 - accuracy: 0.0637 - val_loss: 2.3680 - val_accuracy: 0.0417\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 8s 593ms/step - loss: 2.2923 - accuracy: 0.0609 - val_loss: 2.2770 - val_accuracy: 0.0545\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 8s 590ms/step - loss: 2.1953 - accuracy: 0.0677 - val_loss: 2.2132 - val_accuracy: 0.0605\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 8s 600ms/step - loss: 2.4085 - accuracy: 0.0697 - val_loss: 2.4170 - val_accuracy: 0.0693\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 8s 604ms/step - loss: 2.2274 - accuracy: 0.0719 - val_loss: 2.1843 - val_accuracy: 0.0688\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 9s 689ms/step - loss: 2.0850 - accuracy: 0.0715 - val_loss: 2.1117 - val_accuracy: 0.0645\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 8s 620ms/step - loss: 2.0159 - accuracy: 0.0685 - val_loss: 2.0670 - val_accuracy: 0.0645\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 8s 595ms/step - loss: 1.9814 - accuracy: 0.0679 - val_loss: 2.0447 - val_accuracy: 0.0636\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 8s 603ms/step - loss: 1.9472 - accuracy: 0.0658 - val_loss: 2.0250 - val_accuracy: 0.0621\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 8s 593ms/step - loss: 1.9243 - accuracy: 0.0654 - val_loss: 2.0070 - val_accuracy: 0.0617\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 8s 609ms/step - loss: 1.9012 - accuracy: 0.0643 - val_loss: 2.0033 - val_accuracy: 0.0600\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 8s 590ms/step - loss: 1.8987 - accuracy: 0.0632 - val_loss: 1.9657 - val_accuracy: 0.0607\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 8s 594ms/step - loss: 1.8608 - accuracy: 0.0636 - val_loss: 1.9854 - val_accuracy: 0.0595\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 8s 600ms/step - loss: 1.8354 - accuracy: 0.0633 - val_loss: 1.9404 - val_accuracy: 0.0714\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 8s 593ms/step - loss: 1.8166 - accuracy: 0.1084 - val_loss: 1.9349 - val_accuracy: 0.1326\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 8s 602ms/step - loss: 1.7847 - accuracy: 0.1490 - val_loss: 2.0328 - val_accuracy: 0.1412\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 8s 615ms/step - loss: 1.7796 - accuracy: 0.1706 - val_loss: 1.8940 - val_accuracy: 0.1638\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 8s 608ms/step - loss: 1.7563 - accuracy: 0.1780 - val_loss: 1.9059 - val_accuracy: 0.1657\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 9s 680ms/step - loss: 1.6732 - accuracy: 0.1912 - val_loss: 1.9521 - val_accuracy: 0.1540\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 8s 610ms/step - loss: 1.8068 - accuracy: 0.1748 - val_loss: 1.9259 - val_accuracy: 0.1660\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 8s 598ms/step - loss: 1.7452 - accuracy: 0.1863 - val_loss: 1.8014 - val_accuracy: 0.1764\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 8s 605ms/step - loss: 1.6549 - accuracy: 0.1936 - val_loss: 1.7622 - val_accuracy: 0.1867\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 8s 593ms/step - loss: 1.6060 - accuracy: 0.2043 - val_loss: 1.7403 - val_accuracy: 0.1948\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 8s 603ms/step - loss: 1.5597 - accuracy: 0.2141 - val_loss: 1.8056 - val_accuracy: 0.1907\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 8s 600ms/step - loss: 1.5962 - accuracy: 0.2102 - val_loss: 1.7337 - val_accuracy: 0.2005\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 8s 599ms/step - loss: 1.6053 - accuracy: 0.2122 - val_loss: 1.7185 - val_accuracy: 0.2026\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 8s 605ms/step - loss: 1.5397 - accuracy: 0.2264 - val_loss: 1.7810 - val_accuracy: 0.1986\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 8s 599ms/step - loss: 1.5560 - accuracy: 0.2224 - val_loss: 1.7328 - val_accuracy: 0.2067\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 8s 605ms/step - loss: 1.5308 - accuracy: 0.2304 - val_loss: 1.6613 - val_accuracy: 0.2174\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 8s 590ms/step - loss: 1.4882 - accuracy: 0.2385 - val_loss: 1.7241 - val_accuracy: 0.2093\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 9s 681ms/step - loss: 1.5499 - accuracy: 0.2280 - val_loss: 1.6729 - val_accuracy: 0.2202\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 8s 601ms/step - loss: 1.4871 - accuracy: 0.2412 - val_loss: 1.7576 - val_accuracy: 0.2076\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 8s 596ms/step - loss: 1.5031 - accuracy: 0.2353 - val_loss: 1.6393 - val_accuracy: 0.2193\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 8s 608ms/step - loss: 1.4692 - accuracy: 0.2399 - val_loss: 1.6734 - val_accuracy: 0.2210\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 8s 608ms/step - loss: 1.5166 - accuracy: 0.2334 - val_loss: 1.6335 - val_accuracy: 0.2269\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 8s 598ms/step - loss: 1.5230 - accuracy: 0.2355 - val_loss: 1.6522 - val_accuracy: 0.2257\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 8s 605ms/step - loss: 1.4717 - accuracy: 0.2454 - val_loss: 1.6549 - val_accuracy: 0.2290\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 8s 611ms/step - loss: 1.4349 - accuracy: 0.2555 - val_loss: 1.6070 - val_accuracy: 0.2290\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 8s 609ms/step - loss: 1.4349 - accuracy: 0.2509 - val_loss: 1.6152 - val_accuracy: 0.2331\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 8s 597ms/step - loss: 1.3957 - accuracy: 0.2597 - val_loss: 1.6422 - val_accuracy: 0.2307\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 8s 592ms/step - loss: 1.4083 - accuracy: 0.2605 - val_loss: 1.6016 - val_accuracy: 0.2340\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 8s 595ms/step - loss: 1.3818 - accuracy: 0.2626 - val_loss: 1.5810 - val_accuracy: 0.2405\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 8s 599ms/step - loss: 1.3908 - accuracy: 0.2610 - val_loss: 1.5952 - val_accuracy: 0.2414\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 9s 687ms/step - loss: 1.3788 - accuracy: 0.2647 - val_loss: 1.5998 - val_accuracy: 0.2386\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 8s 599ms/step - loss: 1.4330 - accuracy: 0.2532 - val_loss: 1.6089 - val_accuracy: 0.2357\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 8s 596ms/step - loss: 1.3994 - accuracy: 0.2590 - val_loss: 1.6604 - val_accuracy: 0.2264\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 8s 617ms/step - loss: 1.4118 - accuracy: 0.2558 - val_loss: 1.6388 - val_accuracy: 0.2271\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 8s 614ms/step - loss: 1.3503 - accuracy: 0.2660 - val_loss: 1.5768 - val_accuracy: 0.2426\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 8s 611ms/step - loss: 1.3309 - accuracy: 0.2710 - val_loss: 1.5525 - val_accuracy: 0.2431\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 8s 602ms/step - loss: 1.3762 - accuracy: 0.2629 - val_loss: 1.6400 - val_accuracy: 0.2381\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 8s 600ms/step - loss: 1.3629 - accuracy: 0.2643 - val_loss: 1.6357 - val_accuracy: 0.2300\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 8s 588ms/step - loss: 1.3610 - accuracy: 0.2650 - val_loss: 1.5665 - val_accuracy: 0.2414\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 8s 587ms/step - loss: 1.3593 - accuracy: 0.2646 - val_loss: 1.5906 - val_accuracy: 0.2400\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 8s 586ms/step - loss: 1.3393 - accuracy: 0.2690 - val_loss: 1.5749 - val_accuracy: 0.2390\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 8s 587ms/step - loss: 1.3091 - accuracy: 0.2729 - val_loss: 1.5506 - val_accuracy: 0.2443\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 9s 694ms/step - loss: 1.3228 - accuracy: 0.2714 - val_loss: 1.5963 - val_accuracy: 0.2405\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 8s 594ms/step - loss: 1.3282 - accuracy: 0.2707 - val_loss: 1.5968 - val_accuracy: 0.2364\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 8s 614ms/step - loss: 1.4341 - accuracy: 0.2604 - val_loss: 1.6556 - val_accuracy: 0.2236\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 8s 592ms/step - loss: 1.3721 - accuracy: 0.2711 - val_loss: 1.6409 - val_accuracy: 0.2324\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 8s 606ms/step - loss: 1.3718 - accuracy: 0.2640 - val_loss: 1.5496 - val_accuracy: 0.2438\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 8s 593ms/step - loss: 1.3335 - accuracy: 0.2740 - val_loss: 1.5573 - val_accuracy: 0.2443\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 8s 602ms/step - loss: 1.3037 - accuracy: 0.2782 - val_loss: 1.6998 - val_accuracy: 0.2269\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 8s 608ms/step - loss: 1.3708 - accuracy: 0.2655 - val_loss: 1.5481 - val_accuracy: 0.2460\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 8s 609ms/step - loss: 1.2881 - accuracy: 0.2788 - val_loss: 1.5402 - val_accuracy: 0.2471\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 8s 607ms/step - loss: 1.2586 - accuracy: 0.2860 - val_loss: 1.5190 - val_accuracy: 0.2469\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 8s 609ms/step - loss: 1.2886 - accuracy: 0.2804 - val_loss: 1.5434 - val_accuracy: 0.2460\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 8s 593ms/step - loss: 1.2844 - accuracy: 0.2829 - val_loss: 1.6195 - val_accuracy: 0.2343\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 8s 611ms/step - loss: 1.3660 - accuracy: 0.2692 - val_loss: 1.5992 - val_accuracy: 0.2300\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 9s 683ms/step - loss: 1.3192 - accuracy: 0.2739 - val_loss: 1.5526 - val_accuracy: 0.2526\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 8s 591ms/step - loss: 1.3017 - accuracy: 0.2739 - val_loss: 1.6417 - val_accuracy: 0.2300\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 8s 602ms/step - loss: 1.3336 - accuracy: 0.2720 - val_loss: 1.5385 - val_accuracy: 0.2436\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 8s 601ms/step - loss: 1.2897 - accuracy: 0.2775 - val_loss: 1.5519 - val_accuracy: 0.2455\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 8s 604ms/step - loss: 1.2594 - accuracy: 0.2831 - val_loss: 1.5882 - val_accuracy: 0.2421\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 8s 601ms/step - loss: 1.2822 - accuracy: 0.2811 - val_loss: 1.5646 - val_accuracy: 0.2421\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 8s 598ms/step - loss: 1.3915 - accuracy: 0.2579 - val_loss: 1.6061 - val_accuracy: 0.2345\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 8s 588ms/step - loss: 1.3042 - accuracy: 0.2787 - val_loss: 1.5672 - val_accuracy: 0.2476\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 8s 596ms/step - loss: 1.2757 - accuracy: 0.2824 - val_loss: 1.5448 - val_accuracy: 0.2479\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 8s 588ms/step - loss: 1.2337 - accuracy: 0.2893 - val_loss: 1.5513 - val_accuracy: 0.2531\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 8s 589ms/step - loss: 1.2175 - accuracy: 0.2942 - val_loss: 1.5170 - val_accuracy: 0.2483\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 8s 583ms/step - loss: 1.1971 - accuracy: 0.2970 - val_loss: 1.5228 - val_accuracy: 0.2581\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 11s 848ms/step - loss: 1.3453 - accuracy: 0.2738 - val_loss: 1.5875 - val_accuracy: 0.2462\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 8s 583ms/step - loss: 1.3025 - accuracy: 0.2821 - val_loss: 1.5686 - val_accuracy: 0.2414\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 7s 572ms/step - loss: 1.2384 - accuracy: 0.2921 - val_loss: 1.5495 - val_accuracy: 0.2560\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 8s 595ms/step - loss: 1.2065 - accuracy: 0.2989 - val_loss: 1.5201 - val_accuracy: 0.2514\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 8s 583ms/step - loss: 1.2456 - accuracy: 0.2893 - val_loss: 1.5162 - val_accuracy: 0.2529\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 8s 587ms/step - loss: 1.2048 - accuracy: 0.2991 - val_loss: 1.5412 - val_accuracy: 0.2557\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 8s 584ms/step - loss: 1.2555 - accuracy: 0.2890 - val_loss: 1.6259 - val_accuracy: 0.2393\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 8s 581ms/step - loss: 1.3041 - accuracy: 0.2824 - val_loss: 1.5358 - val_accuracy: 0.2517\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 8s 610ms/step - loss: 1.2083 - accuracy: 0.3002 - val_loss: 1.5222 - val_accuracy: 0.2567\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 8s 602ms/step - loss: 1.1683 - accuracy: 0.3068 - val_loss: 1.5064 - val_accuracy: 0.2645\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 8s 586ms/step - loss: 1.1843 - accuracy: 0.3071 - val_loss: 1.5004 - val_accuracy: 0.2655\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 8s 598ms/step - loss: 1.1747 - accuracy: 0.3064 - val_loss: 1.5423 - val_accuracy: 0.2631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4335b7ff10>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FJxrcAMPaxYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}