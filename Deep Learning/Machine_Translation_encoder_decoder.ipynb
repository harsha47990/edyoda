{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Translation_encoder_decoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ULEAfxF-R_-",
        "outputId": "f8f5b7f6-2943-436c-893f-51afba121ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: helper in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from helper) (3.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install helper\n",
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import pandas as pd\n",
        "\n",
        "english = pd.read_csv('https://raw.githubusercontent.com/Kulbear/deep-learning-nano-foundation/master/DLND-language-translation/data/small_vocab_en',sep=';',names=['data'])\n",
        "french = pd.read_csv('https://raw.githubusercontent.com/Kulbear/deep-learning-nano-foundation/master/DLND-language-translation/data/small_vocab_fr',sep=';',names=['data'])\n",
        "\n",
        "\n",
        "def sentence_padding(x,length=None):\n",
        "  return pad_sequences(x, maxlen=length, padding='post')\n",
        "\n",
        "\n",
        "def inverse_to_text(logits,tokenizer):\n",
        "  index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "  index_to_words[0] = ''\n",
        "  return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "  #Returns the indices of the maximum values along an axis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_tokenize(input,in_token_index,ouput,out_token_index):\n",
        "  counter = 0\n",
        "  for sample in input:                                 \n",
        "    for considered_word in sample.split():\n",
        "      if considered_word not in in_token_index:\n",
        "        in_token_index.update({considered_word : counter + 1})\n",
        "        counter = counter + 1\n",
        "  in_max_length = max([len(i.split()) for i in input])\n",
        "\n",
        "  counter = 0\n",
        "  for sample in ouput:                                 \n",
        "    for considered_word in sample.split():\n",
        "      if considered_word not in out_token_index:\n",
        "        out_token_index.update({considered_word : counter + 1})\n",
        "        counter = counter + 1\n",
        "  out_max_length = max([len(i.split()) for i in ouput])\n",
        "\n",
        "  max_length = max([in_max_length,out_max_length])\n",
        "\n",
        "  features = max([max(in_token_index.values()) + 1,max(out_token_index.values()) + 1])\n",
        "\n",
        "  in_results  = np.zeros(shape = (len(input), max_length, features))  \n",
        "  out_results = np.zeros(shape = (len(ouput), max_length, features))\n",
        "\n",
        "  for i, sample in enumerate(input): \n",
        "    for j, considered_word in list(enumerate(sample.split())):\n",
        "      index = in_token_index.get(considered_word)\n",
        "      in_results[i, j, index] = 1\n",
        "  \n",
        "  for i, sample in enumerate(ouput): \n",
        "    for j, considered_word in list(enumerate(sample.split())):\n",
        "      index = out_token_index.get(considered_word)\n",
        "      out_results[i, j, index] = 1. \n",
        "\n",
        "  #tok.fit_on_texts(lst_sentences)\n",
        "  return in_results,out_results"
      ],
      "metadata": {
        "id": "Z2t9oWv7aVCx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_token_index = {}\n",
        "french_token_index = {}\n",
        "eng_input,french_output = sentence_tokenize(english['data'][0:1000],eng_token_index,french['data'][0:1000],french_token_index)\n",
        "print(eng_input.shape)\n",
        "print(french_output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84OEaURDi1T",
        "outputId": "50a2ab39-501a-4418-e9c6-fd859926976a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 21, 263)\n",
            "(1000, 21, 263)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_decoder(input_shape):\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.003\n",
        "    \n",
        "    # TODO: Build the layers\n",
        "\n",
        "    model = Sequential()\n",
        "    (timesteps,n_features) = input_shape[1:3]\n",
        "    model.add(LSTM(128, activation='relu', input_shape=(timesteps,n_features), return_sequences=True))\n",
        "    model.add(LSTM(64, activation='relu', return_sequences=False))\n",
        "    model.add(RepeatVector(timesteps))\n",
        "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
        "\n",
        "    model.add(TimeDistributed(Dense(n_features)))\n",
        "    model.summary() \n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Train and Print prediction(s)\n",
        "embed_rnn_model = encoder_decoder(eng_input.shape)\n",
        "\n",
        "embed_rnn_model.summary()\n",
        "\n",
        "embed_rnn_model.fit(eng_input, french_output, batch_size=64, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sX96r4PDiOY",
        "outputId": "7ac4034e-138d-4c60-956d-69e69d73a581"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_28 (LSTM)              (None, 21, 128)           200704    \n",
            "                                                                 \n",
            " lstm_29 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " repeat_vector_7 (RepeatVect  (None, 21, 64)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_30 (LSTM)              (None, 21, 64)            33024     \n",
            "                                                                 \n",
            " lstm_31 (LSTM)              (None, 21, 128)           98816     \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 21, 263)          33927     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 415,879\n",
            "Trainable params: 415,879\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_28 (LSTM)              (None, 21, 128)           200704    \n",
            "                                                                 \n",
            " lstm_29 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " repeat_vector_7 (RepeatVect  (None, 21, 64)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_30 (LSTM)              (None, 21, 64)            33024     \n",
            "                                                                 \n",
            " lstm_31 (LSTM)              (None, 21, 128)           98816     \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 21, 263)          33927     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 415,879\n",
            "Trainable params: 415,879\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 7s 273ms/step - loss: 4.7916 - accuracy: 0.0408 - val_loss: 4.3964 - val_accuracy: 0.0405\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 2s 168ms/step - loss: 4.4108 - accuracy: 0.0439 - val_loss: 4.1666 - val_accuracy: 0.0407\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 2s 171ms/step - loss: 5.1842 - accuracy: 0.0379 - val_loss: 7.7674 - val_accuracy: 0.0081\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 2s 170ms/step - loss: 8.2738 - accuracy: 0.0011 - val_loss: 7.9586 - val_accuracy: 9.5238e-04\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 4s 331ms/step - loss: 8.0916 - accuracy: 0.0077 - val_loss: 7.6123 - val_accuracy: 0.0414\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 159ms/step - loss: 7.1148 - accuracy: 0.0480 - val_loss: 5.7053 - val_accuracy: 0.0490\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 2s 155ms/step - loss: 6.8652 - accuracy: 0.0518 - val_loss: 7.2192 - val_accuracy: 0.0402\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: 6.6087 - accuracy: 0.0434 - val_loss: 6.2153 - val_accuracy: 0.0402\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 6.0784 - accuracy: 0.0434 - val_loss: 5.9396 - val_accuracy: 0.0402\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 3s 261ms/step - loss: 5.9657 - accuracy: 0.0434 - val_loss: 4.9828 - val_accuracy: 0.0402\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 2s 156ms/step - loss: 5.9081 - accuracy: 0.0434 - val_loss: 5.1433 - val_accuracy: 0.0402\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 5.5078 - accuracy: 0.0434 - val_loss: 6.2269 - val_accuracy: 0.0402\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 5.5177 - accuracy: 0.0434 - val_loss: 4.4365 - val_accuracy: 0.0402\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 2s 175ms/step - loss: 4.4442 - accuracy: 0.0434 - val_loss: 5.8354 - val_accuracy: 0.0402\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 3s 204ms/step - loss: 5.6050 - accuracy: 0.0434 - val_loss: 6.5065 - val_accuracy: 0.0402\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 2s 154ms/step - loss: 5.4230 - accuracy: 0.0434 - val_loss: 4.5049 - val_accuracy: 0.0402\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: 5.4533 - accuracy: 0.0434 - val_loss: 6.4516 - val_accuracy: 0.0402\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 2s 151ms/step - loss: 5.6141 - accuracy: 0.0434 - val_loss: 5.7076 - val_accuracy: 0.0402\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 3s 204ms/step - loss: 5.3475 - accuracy: 0.0434 - val_loss: 6.0754 - val_accuracy: 0.0402\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 3s 190ms/step - loss: 5.8008 - accuracy: 0.0434 - val_loss: 4.4278 - val_accuracy: 0.0402\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 2s 159ms/step - loss: 4.9944 - accuracy: 0.0434 - val_loss: 6.3288 - val_accuracy: 0.0402\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: 5.8404 - accuracy: 0.0434 - val_loss: 5.4669 - val_accuracy: 0.0402\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 5.4190 - accuracy: 0.0434 - val_loss: 4.5928 - val_accuracy: 0.0402\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 3s 243ms/step - loss: 5.7435 - accuracy: 0.0434 - val_loss: 5.2773 - val_accuracy: 0.0402\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 2s 159ms/step - loss: 5.4635 - accuracy: 0.0434 - val_loss: 5.2768 - val_accuracy: 0.0402\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: 5.4446 - accuracy: 0.0434 - val_loss: 5.6331 - val_accuracy: 0.0402\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: 5.1971 - accuracy: 0.0434 - val_loss: 5.7849 - val_accuracy: 0.0402\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 5.7983 - accuracy: 0.0434 - val_loss: 4.4642 - val_accuracy: 0.0402\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 3s 248ms/step - loss: 5.3416 - accuracy: 0.0434 - val_loss: 5.1818 - val_accuracy: 0.0402\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 5.1793 - accuracy: 0.0434 - val_loss: 6.1088 - val_accuracy: 0.0402\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 5.2411 - accuracy: 0.0434 - val_loss: 5.1898 - val_accuracy: 0.0402\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 5.4606 - accuracy: 0.0434 - val_loss: 4.3894 - val_accuracy: 0.0402\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 5.1890 - accuracy: 0.0434 - val_loss: 4.4842 - val_accuracy: 0.0402\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 3s 183ms/step - loss: 5.7091 - accuracy: 0.0434 - val_loss: 5.9799 - val_accuracy: 0.0402\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: 5.4989 - accuracy: 0.0434 - val_loss: 5.8699 - val_accuracy: 0.0402\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 2s 155ms/step - loss: 5.4996 - accuracy: 0.0434 - val_loss: 4.5032 - val_accuracy: 0.0402\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 4.9079 - accuracy: 0.0434 - val_loss: 4.2974 - val_accuracy: 0.0402\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 3s 231ms/step - loss: 5.5553 - accuracy: 0.0434 - val_loss: 5.1770 - val_accuracy: 0.0402\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 5.3988 - accuracy: 0.0434 - val_loss: 6.2265 - val_accuracy: 0.0402\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: 5.7654 - accuracy: 0.0434 - val_loss: 4.4320 - val_accuracy: 0.0402\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 2s 156ms/step - loss: 5.0090 - accuracy: 0.0434 - val_loss: 4.4079 - val_accuracy: 0.0402\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 5.1249 - accuracy: 0.0434 - val_loss: 6.1389 - val_accuracy: 0.0402\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 3s 248ms/step - loss: 5.0736 - accuracy: 0.0434 - val_loss: 4.4614 - val_accuracy: 0.0402\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: 5.0101 - accuracy: 0.0434 - val_loss: 4.4097 - val_accuracy: 0.0402\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 2s 169ms/step - loss: 5.0817 - accuracy: 0.0434 - val_loss: 4.7246 - val_accuracy: 0.0402\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 5.2989 - accuracy: 0.0434 - val_loss: 6.5391 - val_accuracy: 0.0402\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 2s 188ms/step - loss: 5.3707 - accuracy: 0.0434 - val_loss: 6.3097 - val_accuracy: 0.0402\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 3s 208ms/step - loss: 5.1145 - accuracy: 0.0434 - val_loss: 6.3124 - val_accuracy: 0.0402\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: 5.2126 - accuracy: 0.0434 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 2s 167ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 3s 253ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 3s 244ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 2s 157ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 2s 158ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 3s 235ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 3s 248ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 2s 166ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 2s 185ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 3s 207ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 2s 159ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 2s 167ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 3s 248ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 2s 167ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 3s 240ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 2s 164ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 2s 159ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 2s 193ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 3s 200ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 2s 163ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 2s 162ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 3s 229ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 2s 161ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 2s 154ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 2s 159ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 2s 170ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 3s 250ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 2s 159ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 2s 157ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 2s 163ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 2s 173ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 3s 225ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 2s 169ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 2s 160ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 3s 241ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 2s 163ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 2s 165ms/step - loss: nan - accuracy: 0.3221 - val_loss: nan - val_accuracy: 0.3369\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef00455e50>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FJxrcAMPaxYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}